{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVM",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TthG_W4s0n3Y"
      },
      "source": [
        "SVM Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wu85JWL_ja73",
        "outputId": "3ae261e3-ad4c-41b6-c40f-b7b5309e9bc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import re\n",
        "import nltk\n",
        "from nltk.stem import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import loadmat\n",
        "from PIL import _imaging\n",
        "from sklearn.svm import SVC\n",
        "from numpy import genfromtxt\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "import csv\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.feature_selection import SelectKBest\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def cor_selector(X, y, num_feats):\n",
        "    cor_list = []\n",
        "    feature_name = X.columns.tolist()\n",
        "    # calculate the correlation with y for each feature\n",
        "    for i in X.columns.tolist():\n",
        "        cor = np.corrcoef(X[i], y)[0, 1]\n",
        "        cor_list.append(cor)\n",
        "    # replace NaN with 0\n",
        "    cor_list = [0 if np.isnan(i) else i for i in cor_list]\n",
        "    # feature name\n",
        "    cor_feature = X.iloc[:, np.argsort(\n",
        "        np.abs(cor_list))[-num_feats:]].columns.tolist()\n",
        "    # feature selection? 0 for not select, 1 for select\n",
        "    cor_support = [True if i in cor_feature else False for i in feature_name]\n",
        "    return cor_support, cor_feature\n",
        "\n",
        "\n",
        "data = pd.read_csv('out.csv')\n",
        "df = data\n",
        "df = df.drop(columns=['Label'])\n",
        "X = df\n",
        "print(np.shape(X))\n",
        "y = data['Label']\n",
        "print(np.shape(X))\n",
        "\n",
        "\n",
        "num_feats = 850\n",
        "feature_name = X.columns.tolist()\n",
        "cor_support, cor_feature = cor_selector(X, y, num_feats)\n",
        "\n",
        "our_feature = []\n",
        "\n",
        "our_feature.append([\"Pearson Correlation\", cor_feature])\n",
        "\n",
        "\n",
        "# Chi-Squared\n",
        "X_norm = MinMaxScaler().fit_transform(X)\n",
        "chi_selector = SelectKBest(chi2, k=num_feats)\n",
        "chi_selector.fit(X_norm, y)\n",
        "chi_support = chi_selector.get_support()\n",
        "chi_feature = X.loc[:, chi_support].columns.tolist()\n",
        "\n",
        "\n",
        "our_feature.append([\"Chi-Squared\", chi_feature])\n",
        "\n",
        "# Recursive Feature Elimination\n",
        "rfe_selector = RFE(estimator=LogisticRegression(),\n",
        "                   n_features_to_select=num_feats, step=30, verbose=5)\n",
        "rfe_selector.fit(X_norm, y)\n",
        "rfe_support = rfe_selector.get_support()\n",
        "rfe_feature = X.loc[:, rfe_support].columns.tolist()\n",
        "print(str(len(rfe_feature)), 'selected features')\n",
        "\n",
        "\n",
        "our_feature.append([\"Recursive Feature Elimination\", rfe_feature])\n",
        "\n",
        "\n",
        "# Random Forest\n",
        "\n",
        "embeded_rf_selector = SelectFromModel(\n",
        "    RandomForestClassifier(n_estimators=100), max_features=num_feats)\n",
        "embeded_rf_selector.fit(X, y)\n",
        "\n",
        "embeded_rf_support = embeded_rf_selector.get_support()\n",
        "embeded_rf_feature = X.loc[:, embeded_rf_support].columns.tolist()\n",
        "print(str(len(embeded_rf_feature)), 'selected features')\n",
        "\n",
        "our_feature.append([\"Random Forest\", embeded_rf_feature])\n",
        "\n",
        "# LightGBM\n",
        "\n",
        "\n",
        "lgbc = LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
        "                      reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
        "\n",
        "embeded_lgb_selector = SelectFromModel(lgbc, max_features=num_feats)\n",
        "embeded_lgb_selector.fit(X, y)\n",
        "\n",
        "embeded_lgb_support = embeded_lgb_selector.get_support()\n",
        "embeded_lgb_feature = X.loc[:, embeded_lgb_support].columns.tolist()\n",
        "print(str(len(embeded_lgb_feature)), 'selected features')\n",
        "\n",
        "our_feature.append([\"LightGBM\", embeded_lgb_feature])\n",
        "\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2479, 988)\n",
            "(2479, 988)\n",
            "Fitting estimator with 988 features.\n",
            "Fitting estimator with 958 features.\n",
            "Fitting estimator with 928 features.\n",
            "Fitting estimator with 898 features.\n",
            "Fitting estimator with 868 features.\n",
            "850 selected features\n",
            "206 selected features\n",
            "210 selected features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------- Pearson Correlation ------------------------------\n",
            "(2479, 850)\n",
            "2479\n",
            "Training Accuracy: 100.0 %\n",
            "Test Accuracy: 90.34289713086075 %\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-36590b4e48ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                normalize='true')\n\u001b[1;32m     41\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Confusion matrix for our classifier'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m     \u001b[0mconfusion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mconfusion\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mconfusion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "my_data = pd.read_csv('out.csv')\n",
        "for i in our_feature:\n",
        "    \n",
        "    print(\"---------------------------------------\",\n",
        "          i[0], \"------------------------------\")\n",
        "    # print(my_data.head)\n",
        "    # print(i[1])\n",
        "    df = my_data[i[1]]\n",
        "    # df = my_data\n",
        "    X_ori = np.array(df)\n",
        "    print(np.shape(X_ori))\n",
        "    Y_ori = np.array(my_data['Label'])\n",
        "    # print(type(my_data))\n",
        "\n",
        "    data_length = np.shape(X_ori)[0]\n",
        "    print(data_length)\n",
        "    data_length = 1500\n",
        "    train_len = (int)(data_length*(0.7))\n",
        "    test_len = (data_length-train_len)\n",
        "    y_train = Y_ori[1:train_len]\n",
        "    y_test = Y_ori[train_len:]\n",
        "    X_train = X_ori[1:train_len, :-1]\n",
        "    X_test = X_ori[train_len:, :-1]\n",
        "\n",
        "    # print(X_ori)\n",
        "\n",
        "    eeg_svc = SVC(C=1.0, kernel=\"linear\")\n",
        "    # print(type(eeg_svc))\n",
        "\n",
        "    eeg_svc.fit(X_train, y_train.ravel())\n",
        "    print(\"Training Accuracy:\", (eeg_svc.score(X_train, y_train.ravel()))*100, \"%\")\n",
        "\n",
        "    y_pred = eeg_svc.predict(X_test)\n",
        "    print(\"Test Accuracy:\", (eeg_svc.score(X_test, y_test.ravel()))*100, \"%\")\n",
        "    matrix = plot_confusion_matrix(eeg_svc,\n",
        "                               X_test,\n",
        "                               y_test,\n",
        "                               cmap=plt.cm.Blues,\n",
        "                               normalize='true')\n",
        "    plt.title('Confusion matrix for our classifier')\n",
        "    confusion = confusion_matrix(y_test, y_pred)\n",
        "  \n",
        "    confusion= confusion.flatten()\n",
        "  \n",
        "    print('\\t TP\\tFP\\tTN\\tFN')\n",
        "    print()\n",
        "\n",
        "    print('0.0\\t',confusion[0],'\\t',confusion[1]+confusion[2],'\\t',confusion[4]+confusion[5]+confusion[7]+confusion[8],'\\t',confusion[3]+confusion[6])\n",
        "    print('1.0\\t',confusion[4],'\\t',confusion[3]+confusion[5],'\\t',confusion[0]+confusion[2]+confusion[6]+confusion[8],'\\t',confusion[1]+confusion[7])\n",
        "    print('2.0\\t',confusion[8],'\\t',confusion[6]+confusion[7],'\\t',confusion[0]+confusion[1]+confusion[3]+confusion[4],'\\t',confusion[2]+confusion[5])\n",
        "  \n",
        "    print('\\nClassification Report\\n')\n",
        "    print(classification_report(y_test, y_pred, target_names=['0.0', '1.0', '2.0']))\n",
        "\n",
        "\n",
        "    plt.show()\n",
        "    \n",
        "\n"
      ]
    }
  ]
}